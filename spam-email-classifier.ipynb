{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#                             Email Spam Detection\nThe goal of this project is to develop a robust email spam detection system using machine\nlearning techniques. By analyzing the content and characteristics of emails, the system should\nbe able to accurately classify incoming emails as either spam or legitimate (ham).\n\n![](https://miro.medium.com/v2/resize:fit:920/1*CS-OYdiRLCBMBiOpEURy0g.png)\n\nWe will be exploring below models:\n- Multi-Layer Perceptron (MLP) classifier\n- Multinomial Naive Bayes algorithm\n- Bernoulli Naive Bayes algorithm","metadata":{}},{"cell_type":"markdown","source":"Data Dictionary:\nThe data consist of two columns, \n1. v2 which is the actual email\n2. v1 Label of whether the email is Spam or Ham(not spam)","metadata":{}},{"cell_type":"code","source":"# Import the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.style\nimport seaborn as sns\nimport nltk #Natural Language Toolkit\n#To ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","metadata":{"execution":{"iopub.status.busy":"2023-09-22T18:54:03.891186Z","iopub.execute_input":"2023-09-22T18:54:03.891508Z","iopub.status.idle":"2023-09-22T18:54:06.548617Z","shell.execute_reply.started":"2023-09-22T18:54:03.891483Z","shell.execute_reply":"2023-09-22T18:54:06.547177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Loading the dataset","metadata":{}},{"cell_type":"code","source":"#Load data & print samples\ndf = pd.read_csv('/kaggle/input/email-spam-detection-dataset-classification/spam.csv',encoding='latin-1')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:34:37.779573Z","iopub.execute_input":"2023-09-21T14:34:37.780268Z","iopub.status.idle":"2023-09-21T14:34:37.843619Z","shell.execute_reply.started":"2023-09-21T14:34:37.780229Z","shell.execute_reply":"2023-09-21T14:34:37.842478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's drop the non-relevant unnamed columns \ndf=df.drop(['Unnamed: 2', 'Unnamed: 3','Unnamed: 4'],axis=1)\n\n# Renaming v1 & v2 as Category & Text\ndf=df.rename(columns={\"v1\":\"Category\",\"v2\":\"Text\"})\n\n#Sample post modifications\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:34:37.845458Z","iopub.execute_input":"2023-09-21T14:34:37.846231Z","iopub.status.idle":"2023-09-21T14:34:37.86656Z","shell.execute_reply.started":"2023-09-21T14:34:37.846177Z","shell.execute_reply":"2023-09-21T14:34:37.864987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"#Let's check the length of the dataset\nprint(\" Total number of rows in the dataset are\", len(df))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:34:37.868223Z","iopub.execute_input":"2023-09-21T14:34:37.868679Z","iopub.status.idle":"2023-09-21T14:34:37.881467Z","shell.execute_reply.started":"2023-09-21T14:34:37.868634Z","shell.execute_reply":"2023-09-21T14:34:37.880338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's check the distribution of the Ham & Spam\n\nprint('Label distribution (%):', round(df.Category.value_counts(normalize=True),3)*100)\nplt.figure(figsize=(8,2))\nax=sns.countplot(data=df, y='Category')\nfor container in ax.containers:\n    ax.bar_label(container)\nplt.tight_layout()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:34:37.885009Z","iopub.execute_input":"2023-09-21T14:34:37.886201Z","iopub.status.idle":"2023-09-21T14:34:38.175308Z","shell.execute_reply.started":"2023-09-21T14:34:37.886154Z","shell.execute_reply":"2023-09-21T14:34:38.174467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The dataset has **4825 emails (86.6%)** labled as Ham while **747 (13.4%)** labaled as Spam.","metadata":{}},{"cell_type":"code","source":"#Descriptive Summary of the dataset\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:34:38.176485Z","iopub.execute_input":"2023-09-21T14:34:38.177184Z","iopub.status.idle":"2023-09-21T14:34:38.199475Z","shell.execute_reply.started":"2023-09-21T14:34:38.17715Z","shell.execute_reply":"2023-09-21T14:34:38.198643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- \"ham\" is the predominant category.\n- The dataset contains 5,169 unique texts.\n- The most frequent text being \"Sorry, I'll call later,\" occurring 30 times.\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"#Let's create a column to check of each text & plot a histogram to check the distirbution\ndf['Length']=df['Text'].apply(len)\ndisplay(df.head())\n\n#distribution of the data\nimport plotly.express as px\nfig = px.histogram(df, x='Length', marginal='rug',\n                   title='Histogram of Text Length')\nfig.update_layout(\n    xaxis_title='Length',\n    yaxis_title='Frequency',\n    showlegend=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:34:38.200694Z","iopub.execute_input":"2023-09-21T14:34:38.201458Z","iopub.status.idle":"2023-09-21T14:34:41.087358Z","shell.execute_reply.started":"2023-09-21T14:34:38.201422Z","shell.execute_reply":"2023-09-21T14:34:41.086424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets check the distribution against categories\nimport plotly.express as px\nfig = px.histogram(df, x='Length', color='Category', marginal='rug',\n                   title='Histogram of Text Length by Category')\nfig.update_layout(\n    xaxis_title='Length',\n    yaxis_title='Frequency',\n    showlegend=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:34:41.088648Z","iopub.execute_input":"2023-09-21T14:34:41.08936Z","iopub.status.idle":"2023-09-21T14:34:41.203166Z","shell.execute_reply.started":"2023-09-21T14:34:41.089325Z","shell.execute_reply":"2023-09-21T14:34:41.20202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's Label the data as 0 & 1 i.e. Spam as 1 & Ham as 0\ndf.loc[:,'Category']=df.Category.map({'ham':0, 'spam':1})\ndf['Category'] = df['Category'].astype(int)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:34:41.204457Z","iopub.execute_input":"2023-09-21T14:34:41.204788Z","iopub.status.idle":"2023-09-21T14:34:41.218092Z","shell.execute_reply.started":"2023-09-21T14:34:41.204758Z","shell.execute_reply":"2023-09-21T14:34:41.217222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:34:41.219544Z","iopub.execute_input":"2023-09-21T14:34:41.219879Z","iopub.status.idle":"2023-09-21T14:34:41.380015Z","shell.execute_reply.started":"2023-09-21T14:34:41.21985Z","shell.execute_reply":"2023-09-21T14:34:41.378778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Bag of words","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\ncount = CountVectorizer()\ntext = count.fit_transform(df['Text'])\n#Train & test split\nx_train, x_test, y_train, y_test = train_test_split(text, df['Category'], test_size=0.30, random_state=100)\ntext","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:34:41.381487Z","iopub.execute_input":"2023-09-21T14:34:41.381922Z","iopub.status.idle":"2023-09-21T14:34:41.509142Z","shell.execute_reply.started":"2023-09-21T14:34:41.38188Z","shell.execute_reply":"2023-09-21T14:34:41.508021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's print the dimentions of the train & test dataset\ndisplay('X-Train :', x_train.shape)\ndisplay('X-Test :',x_test.shape)\ndisplay('Y-Train :',y_train.shape)\ndisplay('X-Test :',y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:34:41.510486Z","iopub.execute_input":"2023-09-21T14:34:41.511062Z","iopub.status.idle":"2023-09-21T14:34:41.53362Z","shell.execute_reply.started":"2023-09-21T14:34:41.511022Z","shell.execute_reply":"2023-09-21T14:34:41.532358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training the ML model\nUsing Neural Network\n![](https://static.javatpoint.com/tutorial/tensorflow/images/multi-layer-perceptron-in-tensorflow.png)","metadata":{}},{"cell_type":"code","source":"\n%%time\nfrom sklearn.neural_network import MLPClassifier\n\nmlp_classifier_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000) \nmlp_classifier_model.fit(x_train, y_train)  \n\nprediction = mlp_classifier_model.predict(x_test)\n\n# Calculate and print classification metrics\nprint(\"MLP Classifier\")\nprint(\"Accuracy score: {:.2f}\".format(accuracy_score(y_test, prediction)))\nprint(\"Precision score: {:.2f}\".format(precision_score(y_test, prediction)))\nprint(\"Recall score: {:.2f}\".format(recall_score(y_test, prediction)))\nprint(\"F1 score: {:.2f}\".format(f1_score(y_test, prediction)))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:59:34.201197Z","iopub.execute_input":"2023-09-21T14:59:34.201578Z","iopub.status.idle":"2023-09-21T14:59:55.204137Z","shell.execute_reply.started":"2023-09-21T14:59:34.201548Z","shell.execute_reply":"2023-09-21T14:59:55.202992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Multinomial Naive Bayes model \nfrom sklearn.naive_bayes import MultinomialNB\n\nmultinomial_nb_model = MultinomialNB()\nmultinomial_nb_model.fit(x_train, y_train)  # Train the model\n\nprediction = multinomial_nb_model.predict(x_test)\n\nprint(\"Multinomial NB\")\nprint(\"Accuracy score: {}\". format(accuracy_score(y_test, prediction)) )\nprint(\"Precision score: {}\". format(precision_score(y_test, prediction)) )\nprint(\"Recall score: {}\". format(recall_score(y_test, prediction)))\nprint(\"F1 score: {}\". format(f1_score(y_test, prediction)))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:59:55.206049Z","iopub.execute_input":"2023-09-21T14:59:55.21129Z","iopub.status.idle":"2023-09-21T14:59:55.24261Z","shell.execute_reply.started":"2023-09-21T14:59:55.211226Z","shell.execute_reply":"2023-09-21T14:59:55.241517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Bernoulli Naive Bayes model\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nbernoulli_nb_model = BernoulliNB()\nbernoulli_nb_model.fit(x_train, y_train)\n\nprediction = bernoulli_nb_model.predict(x_test)\n\n#Evaluation\nprint(\"Bernoulli NB\")\nprint(\"Accuracy score: {}\". format(accuracy_score(y_test, prediction)) )\nprint(\"Precision score: {}\". format(precision_score(y_test, prediction)) )\nprint(\"Recall score: {}\". format(recall_score(y_test, prediction)))\nprint(\"F1 score: {}\". format(f1_score(y_test, prediction)))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T14:55:08.561717Z","iopub.execute_input":"2023-09-21T14:55:08.562147Z","iopub.status.idle":"2023-09-21T14:55:08.591577Z","shell.execute_reply.started":"2023-09-21T14:55:08.562113Z","shell.execute_reply":"2023-09-21T14:55:08.590419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confusion Matrix Subplot for 3 Models\nfrom sklearn.metrics import confusion_matrix\nmodels = [(\"Multinomial NB\", multinomial_nb_model), (\"Bernoulli NB\", bernoulli_nb_model),(\"MLP Classifier\", mlp_classifier_model) ]\n\nfig, axes = plt.subplots(1, 3, figsize=(10, 3))\nfor i, (model_name, model) in enumerate(models):\n    prediction = model.predict(x_test)\n    cm = confusion_matrix(y_test, prediction)\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=axes[i])\n    axes[i].set_title(f\"{model_name} - Confusion Matrix\")\n    axes[i].set_xlabel(\"Predicted\")\n    axes[i].set_ylabel(\"Actual\")\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T15:28:04.005753Z","iopub.execute_input":"2023-09-21T15:28:04.006162Z","iopub.status.idle":"2023-09-21T15:28:04.638931Z","shell.execute_reply.started":"2023-09-21T15:28:04.00613Z","shell.execute_reply":"2023-09-21T15:28:04.637647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Metric Comparison Heatmap\nmetric_data = []\nfor model_name, model in models:\n    prediction = model.predict(x_test)\n    accuracy = accuracy_score(y_test, prediction)\n    precision = precision_score(y_test, prediction)\n    recall = recall_score(y_test, prediction)\n    f1 = f1_score(y_test, prediction)\n    metric_data.append([accuracy, precision, recall, f1])\nmetric_labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n#heatmap for metric comparison\nplt.figure(figsize=(6, 3))\nsns.heatmap(metric_data, annot=True, fmt=\".2f\", cbar=False, cmap=\"summer_r\", xticklabels=metric_labels, yticklabels=[model_name for model_name, _ in models])\nplt.title(\"Metric Comparison\")\nplt.yticks(rotation=0)\nplt.xlabel(\"Metrics\")\nplt.ylabel(\"Models\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T15:28:05.970021Z","iopub.execute_input":"2023-09-21T15:28:05.970438Z","iopub.status.idle":"2023-09-21T15:28:06.294201Z","shell.execute_reply.started":"2023-09-21T15:28:05.970405Z","shell.execute_reply":"2023-09-21T15:28:06.292748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Conclusion:\n* All three models perform exceptionally well, with high accuracy scores.\n* MLP Classifier leads in accuracy of 99%, followed by Bernoulli NB (98.39%), and Multinomial NB (98.15%)\n* Bernoulli NB achieves perfect precision (100%), indicating it has predicated correctly all the time.\n* MLP Classifier excels in F1 score of 94%\n* MLP Classifier has slightly lower recall 90% but compensates with higher precision.\n\n> **The final choice of model always depend upon what is needed to be filtered & hence model can be adjusted to improve recall or precision.**\n> - If you want to  minimize the number of false negatives i.e spam messages don't end up in the user's inbox you would like to have high Recall.\n> - On the other hand with high precision(false negatives), one might miss important messages because the model is overly cautious in classifying messages as spam.","metadata":{}}]}